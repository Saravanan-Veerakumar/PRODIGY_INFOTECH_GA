{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a9cd72",
   "metadata": {},
   "source": [
    "# Project: \"Text-to-Image Generator with Stable Diffusion\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757772e-5a9d-491f-8b67-d859a818f368",
   "metadata": {},
   "source": [
    "## Utilize pre-trained generative models like DALL-E-mini or Stable Diffusion to create images from text prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9249d",
   "metadata": {},
   "source": [
    "In this example, let’s focus on using Stable Diffusion via the popular diffusers library from Hugging Face, which simplifies working with such models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c365acb0",
   "metadata": {},
   "source": [
    "### Project Overview"
   ]
  },
  {
   "cell_type": "raw",
   "id": "797e01e1",
   "metadata": {},
   "source": [
    "This project will take a user-provided text prompt and generate an image based on it using the Stable Diffusion model. We'll use Python for implementation and Hugging Face’s diffusers library to access the pre-trained model. The project will allow users to input text, select image dimensions, and output the generated image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9da9c",
   "metadata": {},
   "source": [
    "#### Set up Environment"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2a5a731",
   "metadata": {},
   "source": [
    "Setting up the environment with necessary packages. Here’s a list of libraries you will need:\n",
    "\n",
    "* transformers: Hugging Face's library for accessing pre-trained models.\n",
    "* diffusers: Hugging Face's library specifically for diffusion models (including Stable Diffusion).\n",
    "* torch: For running machine learning models.\n",
    "* Pillow: For image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ff8250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:08:00.955513Z",
     "start_time": "2024-10-05T15:07:47.611419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sarav\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Collecting diffusers\n",
      "  Obtaining dependency information for diffusers from https://files.pythonhosted.org/packages/d1/1c/2ad4e336fe8d83865810f32717a6b38ece3e90c2acc441cfadb5ce950eda/diffusers-0.30.3-py3-none-any.whl.metadata\n",
      "  Downloading diffusers-0.30.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\sarav\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\sarav\\anaconda3\\lib\\site-packages (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from diffusers) (6.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from diffusers) (0.25.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from diffusers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from diffusers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from diffusers) (0.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from importlib-metadata->diffusers) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from requests->diffusers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from requests->diffusers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from requests->diffusers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from requests->diffusers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading diffusers-0.30.3-py3-none-any.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.7 MB 2.8 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.3/2.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.5/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.6/2.7 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.7 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.9/2.7 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.0/2.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.2/2.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.4/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.7/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.9/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.0/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.1/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.3/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.4/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.6/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: diffusers\n",
      "Successfully installed diffusers-0.30.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch diffusers transformers pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d521352",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9aa511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:09:32.047521Z",
     "start_time": "2024-10-05T15:09:00.788453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sarav\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarav\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\Users\\Sarav\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3a61e",
   "metadata": {},
   "source": [
    "#### Load the Stable Diffusion Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d6aab2e",
   "metadata": {},
   "source": [
    "We will load the Stable Diffusion model using the Hugging Face diffusers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23500c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:40:43.716398Z",
     "start_time": "2024-10-05T15:10:23.497801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3551dcd6daf40dfa50c3afa27887acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarav\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sarav\\.cache\\huggingface\\hub\\models--CompVis--stable-diffusion-v1-4. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de197108fb184fa99f16da59095586d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f045012d0344f78af3e664fd550bed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "safety_checker/config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e362b7d5004c95b40931bce700a7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf25fd241b2c4fcab71fb0e51449c90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae84673b54c4c6fa92344ec2757b51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)kpoints/scheduler_config-checkpoint.json:   0%|          | 0.00/209 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c0ed196499482b853291c96b782194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df38917bd294549a26e59d11112c981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2210798ffa4dc99dbca9f6ed5c6176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d8d52bd0644ea08127cbafdb0a7d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c9cafebbf04504850138c474be484f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5afa519949b4706a45526be67ca689e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506c92fe07af4a129a8a40a374b0cbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac88a9d341c241f5a521b85db3d0e67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b95cb889f9942b48d59e1659ad1611a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80eb647ccdd34aca9b71731e5851d535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98052504dec4d45ae48ad3c3597a534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dda1d14c0c649e18262162d7f5efa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained Stable Diffusion model from Hugging Face\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id)\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8fc39",
   "metadata": {},
   "source": [
    "#### Generate Image from Text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7e4d056",
   "metadata": {},
   "source": [
    "Creating a function that takes a text prompt from the user and generates an image using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59a435a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:44:34.270415Z",
     "start_time": "2024-10-05T15:44:34.263169Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_image(prompt, image_size=(512, 512)):\n",
    "    # Generate an image from the text prompt\n",
    "    with torch.autocast(device):\n",
    "        image = pipe(prompt)[\"images\"][0]  # Get the generated image\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e405052",
   "metadata": {},
   "source": [
    "#### Save or Display the Generated Image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bec96ce",
   "metadata": {},
   "source": [
    "Once the image is generated, you can either display it or save it to the disk using Pillow library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "591e1b86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:44:38.478287Z",
     "start_time": "2024-10-05T15:44:38.471719Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_image(image, filename=\"generated_image.png\"):\n",
    "    # Save the image to disk\n",
    "    image.save(filename)\n",
    "    print(f\"Image saved as {filename}\")\n",
    "\n",
    "def show_image(image):\n",
    "    # Display the image\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84af4c26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:40:45.685836Z",
     "start_time": "2024-10-05T15:40:45.685836Z"
    }
   },
   "source": [
    "#### Main Function to Run the Project"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7669be4",
   "metadata": {},
   "source": [
    "This function will handle user input, generate an image, and display/save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceddc439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T16:46:45.863948Z",
     "start_time": "2024-10-05T15:44:41.402814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your text prompt: CAT AND DOG FIGHTING EACH OTHER\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184aa976a7b34f69b72027ba03f3bfca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as generated_image.png\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Get text prompt from user\n",
    "    prompt = input(\"Enter your text prompt: \")\n",
    "\n",
    "    # Generate image based on prompt\n",
    "    generated_image = generate_image(prompt)\n",
    "\n",
    "    # Save and show the image\n",
    "    show_image(generated_image)\n",
    "    save_image(generated_image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a923b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
